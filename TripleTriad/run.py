'''
Created on Dec 13, 2018

@author: Mengliao Wang

This is the main file to execute the training process for TripleTriadMaster.
It can do the following:
    1) start the training and self-play processes in the background.
    2) Find the best policy trained so far by training module, for self-play module to play against itself
    3) Push the games generated by the self-play module to the games pool, so training module can utilize them
    4) Call evaluation module to evaluate the policy generated by
'''

from TripleTriad.training.zero_train import run_training
from TripleTriad.selfplay import self_play
from TripleTriad.player.ZeroNN import ZeroPolicy
from TripleTriad.feature import DEFAULT_FEATURES
from Benchmark.evaluate import compare_policy

import multiprocessing
import time
import argparse
import os

# How many process that can train in parallel
DEFAULT_TRAINING_PROCESSORS = 1
# How many process that can self play in parallel
DEFAULT_SELFPLAY_PROCESSORS = 4
# The max size of the game pool
MAX_POOL_SIZE = 500000
# Best policy weight file name
BEST_POLICY_WEIGHT = 'weight.best.hdf'
# the default path to card files
DEFAULT_CARD_PATH = '/home/mike/tmp/TripleTriadOutput'
# the default card file name
DEFAULT_CARD_FILE= '10_cards.csv'
# Number of games to evaluate
EVAL_GAME_NUMBERS = 400
# Threshold of win rate to
WIN_RATE_THRESHOLD = 0.36
# Number of games that the current best_player will play again itself
SELF_PLAY_GAMES = 25000

MCTS_SIMULATIONS = 1600


class TrainManager():
    def __init__(self, out_dir, card_path = DEFAULT_CARD_PATH, card_file = DEFAULT_CARD_FILE):
        self.out_dir = out_dir
        self.card_path = card_path
        self.card_file = card_file
        self.new_game_queue = multiprocessing.Queue()
        self.game_pool = multiprocessing.Queue(MAX_POOL_SIZE)

    def start_manager(self):
        # this is the main thread that update the game pool every minute
        loop_count = 0
        while True:
            loop_count = loop_count + 1
            time.sleep(60)
            if self.new_game_queue.qsize() > SELF_PLAY_GAMES:
                self.update_pool()
            self.update_pool()
            # Every 30 minutes save the current game pool to disk
            if loop_count % 30 == 0:
                self.save_game_pool()

    def start_training_processes(self, processors = DEFAULT_TRAINING_PROCESSORS):
        workers = []
        for i in range(processors):
            p = multiprocessing.Process(target=run_training, args=(self.game_pool,))
        for worker in workers:
            worker.start()

    def start_selfplay_processes(self, processors = DEFAULT_SELFPLAY_PROCESSORS):
        workers = []
        for i in range(processors):
            p = multiprocessing.Process(target=self_play, args=(self.new_game_queue,))
        for worker in workers:
            worker.start()

    def get_best_policy(self):
        policy = ZeroPolicy(self.out_dir, DEFAULT_FEATURES)
        policy.load_weights(BEST_POLICY_WEIGHT)
        return policy

    def save_best_policy(self, policy):
        policy.save_weights(BEST_POLICY_WEIGHT)

    def evaluate_policy(self, policy):
        target = self.get_best_policy()
        win_rate = compare_policy(policy, target, EVAL_GAME_NUMBERS, DEFAULT_CARD_PATH, DEFAULT_CARD_FILE)
        if win_rate > WIN_RATE_THRESHOLD:
            self.save_best_policy(policy)

    def update_pool(self):
        iter = 0
        print("Updating pool... there are currently {} in the new game pool".format(self.new_game_queue.qsize()))
        # Each time we only add the number of self-played games from the best player to the queue
        while not self.new_game_queue.empty() and iter < SELF_PLAY_GAMES:
            # Move the old games out of the pool
            if self.game_pool.full():
                self.game_pool.get()
            self.game_pool.put(self.new_game_queue.get())
            iter = iter + 1

    def save_game_pool(self):
        # TODO: Save the game pool to disk
        pass


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Start the training and self play processes')
    parser.add_argument("out_dir",help="Path to where the model params and metadata will be saved")
    args = parser.parse_args()

    master = TrainManager(args.out_dir)
    master.start_selfplay_processes()
    master.start_training_processes()
    master.start_manager()
